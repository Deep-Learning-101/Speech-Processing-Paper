#
https://www.twman.org/AI/ASR

https://huggingface.co/DeepLearning101

https://deep-learning-101.github.io/Speech-Processing
#

## ğŸ™ï¸ èªéŸ³è­˜åˆ¥ / åˆæˆå¹³å°åƒ¹æ ¼æ¯”è¼ƒ
~2025/04
| åç¨± | åŠŸèƒ½ | ç¶²å€ | èªªæ˜ |
|------|------|------|------|
| [Whisper (é–‹æº)](https://github.com/openai/whisper) | èªéŸ³è­˜åˆ¥ã€ç¿»è­¯ | æ¯åˆ†é˜150å­— Ã— 10åˆ†é˜ = 1500å­— |
| [Fish Audio](https://speech.fish.audio/zh/) | èªéŸ³è­˜åˆ¥ã€èªéŸ³åˆæˆ | TTSï¼šè‹±æ–‡ $0.0225ï¼Œä¸­æ–‡ $0.0675ï¼›ASRï¼š30åˆ†é˜ = $0.18 |
| [Deepgram](https://deepgram.com/pricing) | èªéŸ³è­˜åˆ¥ | TTSï¼šè‹±æ–‡ $0.02025ï¼Œä¸­æ–‡ $0.06075ï¼›ASRï¼š30åˆ†é˜ = $0.147 |
| [Microsoft Azure](https://azure.microsoft.com/zh-tw/pricing/details/cognitive-services/speech-services/) | èªéŸ³åˆæˆ | TTSï¼šè‹±æ–‡ $0.036ï¼Œä¸­æ–‡ $0.108ï¼›ASRï¼šå³æ™‚è½‰éŒ„ $1/å°æ™‚ï¼Œè¶…é¡ $0.8/å°æ™‚ |
| [Amazon Polly](https://aws.amazon.com/tw/polly/pricing) | èªéŸ³åˆæˆ | TTSï¼šè‹±æ–‡ $0.024ï¼Œä¸­æ–‡ $0.072 |
| [Google WaveNet](https://cloud.google.com/text-to-speech/pricing) | èªéŸ³åˆæˆ | TTSï¼šè‹±æ–‡ $0.024ï¼Œä¸­æ–‡ $0.072 |
| [Google Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/pricing?hl=zh-tw#gemini-models) | å¤§å‹èªè¨€æ¨¡å‹ | Gemini/Claude å®šåƒ¹é  |
| [Google Cloud VM](https://cloud.google.com/compute/vm-instance-pricing?hl=zh-tw#sharedcore_machine_types) | è™›æ“¬æ©Ÿå™¨ | VM åŸ·è¡Œå€‹é«”å®šåƒ¹é é¢ |

---

## Speech-Processing
**èªéŸ³è™•ç† (Speech Processing)**

- 2025-05-14ï¼š[ten-turn-detection](https://zread.ai/TEN-framework/ten-turn-detection)ï¼›[ten-vad](https://zread.ai/TEN-framework/ten-vad)
- 2025-01-19ï¼š[å°ç±³èªéŸ³é¦–å¸­ç§‘å­¸å®¶Daniel Poveyï¼šèªéŸ³è¾¨è­˜æ²å®Œäº†ï¼Œä¸‹ä¸€å€‹æ©Ÿæœƒåœ¨å“ªè£¡ï¼Ÿ](https://www.jiqizhixin.com/articles/2025-01-19-4?)
-  [ASR/TTS é–‹ç™¼é¿å‘æŒ‡å—ï¼šèªéŸ³è¾¨è­˜èˆ‡åˆæˆçš„å¸¸è¦‹æŒ‘æˆ°èˆ‡å°ç­–](https://blog.twman.org/2024/02/asr-tts.html)ï¼›[æ¢è¨ ASR å’Œ TTS æŠ€è¡“æ‡‰ç”¨ä¸­çš„å•é¡Œï¼Œå¼·èª¿æ•¸æ“šè³ªé‡çš„é‡è¦æ€§](https://deep-learning-101.github.io/asr-tts)
-  [é‚£äº›èªéŸ³è™•ç†è¸©çš„å‘](https://blog.twman.org/2021/04/ASR.html)ï¼›[åˆ†äº«èªéŸ³è™•ç†é ˜åŸŸçš„å¯¦å‹™ç¶“é©—ï¼Œå¼·èª¿è³‡æ–™å“è³ªå°æ¨¡å‹æ•ˆæœçš„å½±éŸ¿](https://deep-learning-101.github.io/speech)
- [éŸ³è¦–é »é–‹ç™¼åŸºç¤å…¥é–€ï½œè²éŸ³çš„æ¡é›†èˆ‡é‡åŒ–ã€éŸ³é »æ•¸å­—ä¿¡è™Ÿè³ªé‡ã€éŸ³é »ç¢¼ç‡](https://zhuanlan.zhihu.com/p/577850804)
- [ä¸€æ–‡ç¸½è¦½è¬å­—èªéŸ³åˆæˆç³»åˆ—åŸºç¤èˆ‡è«–æ–‡ç¸½çµ](https://mp.weixin.qq.com/s/S9T9fk9THUF3JQRnNuOM7Q)
- [Mozilla Common Voice Datasets - zhTW](https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0/viewer/zh-TW)
- [èªéŸ³è­˜åˆ¥è³‡æ–™åŒ¯ç¸½ï¼šå¸¸è¦‹åº«å’Œç‰¹å¾µå°æ¯”](https://zhuanlan.zhihu.com/p/616020595)
- [èªéŸ³åˆæˆ,èªéŸ³è¾¨è­˜å¸¸è¦‹è³‡æ–™é›†](https://mp.weixin.qq.com/s/xGAEzuT5x7BkTRH6DCJFhA)


## Speech-Recognition
**ä¸­æ–‡èªéŸ³è­˜åˆ¥ (Chinese Speech Recognition)**

[https://www.twman.org/AI/ASR](https://www.twman.org/AI/ASR)

é€šéèªéŸ³ä¿¡è™Ÿè™•ç†å’Œæ¨¡å¼è­˜åˆ¥è®“æ©Ÿå™¨è‡ªå‹•è­˜åˆ¥å’Œç†è§£äººé¡çš„å£è¿°

* 2025-11-15ï¼š[Omnilingual-ASR](https://github.com/facebookresearch/omnilingual-asr)ï¼›[DEMO](https://aidemos.atmeta.com/omnilingualasr/language-globe)
* 2025-09-19ï¼š[Canary-1b-v2_NVIDIA](https://huggingface.co/nvidia/canary-1b-v2)ï¼›[æ¨å‹•èªéŸ³AI å‰µæ–°ï¼šNVIDIA ç™¼å¸ƒå¤šèªç¨®èªéŸ³AI é–‹æ”¾è³‡æ–™é›†èˆ‡æ¨¡å‹](https://zhuanlan.zhihu.com/p/1952436345222993067)
* 2025-08-29ï¼š[WhisperLiveKit](http://github.com/QuentinFuxa/WhisperLiveKit)ï¼›[åˆ¥å†è£¸è·‘Whisper äº†ï¼é€™å€‹é–‹æºç¥å™¨ï¼Œè®“å³æ™‚èªéŸ³è½‰å¯«çµ²æ»‘å¾—ä¸åƒè©±](https://zhuanlan.zhihu.com/p/1944712252512010607)
* 2025-07-16ï¼š[Voxtral Small 1.0 (24B) - 2507](https://huggingface.co/mistralai/Voxtral-Small-24B-2507)ï¼›[Voxtral-Mini-3B-250](https://huggingface.co/mistralai/Voxtral-Mini-3B-2507)ï¼›[Mistralé¦–å€‹é–‹æºèªéŸ³æ¨¡å‹ä¾†äº†ï¼å¤šé …æ¸¬è©¦è¶…è¶ŠGPT-4o mini](https://zhuanlan.zhihu.com/p/1928945056955471125)
* 2025-07-02ï¼š[OpusLM](https://huggingface.co/espnet/OpusLM_7B_Anneal)ï¼š[å…¨é–‹æºï¼ CMU ç™¼å¸ƒOpusLMï¼šçµ±ä¸€èªéŸ³è¾¨è­˜ã€åˆæˆã€æ–‡å­—ç†è§£çš„å¤§æ¨¡å‹](https://mp.weixin.qq.com/s/XCgBTgfOs8y_fFFEEMrW-w)
* 2025-06-06ï¼š[speakr](https://github.com/murtaza-nasir/speakr)ï¼›[é–‹æºçš„è½‰éŒ„éŸ³è¨Šè¨˜éŒ„å·¥å…·ï¼Œæ›´å¤ è¨­å®šéŸ³è¨Šè½‰éŒ„èªè¨€å’ŒAI ç”Ÿæˆå…§å®¹](https://cloud.tencent.com/developer/news/2645205)
* 2025-05-06ï¼š[VITA-Audio](https://deepwiki.com/VITA-MLLM/VITA-Audio)ï¼›[VITA-Audioï¼šå¿«é€Ÿäº¤éŒ¯è·¨æ¨¡æ…‹ä»¤ç‰Œç”Ÿæˆï¼Œç”¨æ–¼é«˜æ•ˆçš„å¤§å‹èªéŸ³èªè¨€æ¨¡å‹](https://www.alphaxiv.org/zh/overview/2505.03739)
* 2025-04-28ï¼š[FireRedASR](https://github.com/FireRedTeam/FireRedASR)ï¼š[AIèªéŸ³åŠ©ç†èªéŸ³è½‰æ–‡å­—FireRedASRè½‰API](https://mp.weixin.qq.com/s/FUC-rSkItxEQJIWUbU4Cpw)ï¼›[å¦‚ä½•ä½¿ç”¨](https://deepwiki.com/search/_ca59f67a-33b7-4008-8ac0-296d135051ea)
* 2025-04-02ï¼š[Dolphin](https://github.com/DataoceanAI/Dolphin)ï¼›[Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages](https://arxiv.org/abs/2503.20212)
* 2024/07/03ï¼š[SenseVoice](https://funaudiollm.github.io/)ï¼š[é˜¿é‡Œé–‹æºèªéŸ³å¤§æ¨¡å‹ï¼šèªéŸ³è¾¨è­˜æ•ˆæœèˆ‡è¡¨ç¾å¼·æ–¼Whisperï¼Œé‚„èƒ½åµæ¸¬æŒè²ã€ç¬‘è²ã€å’³å—½ç­‰ï¼](https://mp.weixin.qq.com/s/q-DyyAQikz8nSNm6qMwZKQ)
* 2024/05/01ï¼š[ä½¿ç”¨Hugging Face æ¨ç†çµ‚ç«¯å»ºç«‹å¼·å¤§çš„ã€ŒèªéŸ³è¾¨è­˜+ èªªè©±è€…åˆ†å‰²+ æŠ•æ©Ÿè§£ç¢¼ã€å·¥ä½œæµç¨‹](https://huggingface.co/blog/zh/asr-diarization)

---

* **Whisper**
    * [Whisper: openAIé–‹æºæº–ç¢ºç‡æœ€é«˜çš„é€šç”¨èªè¨€èªéŸ³è­˜åˆ¥](https://zhuanlan.zhihu.com/p/634462613)
    * [Robust Speech Recognition via Large-Scale Weak Supervision](https://cdn.openai.com/papers/whisper.pdf)
    * [Introducing Whisper](https://openai.com/research/whisper)
      * [WhisperLiveKit](https://github.com/QuentinFuxa/WhisperLiveKit)ï¼š[åˆ¥å†è£¸è·‘Whisper äº†ï¼é€™å€‹é–‹æºç¥å™¨ï¼Œè®“å³æ™‚èªéŸ³è½‰å¯«çµ²æ»‘å¾—ä¸åƒè©±](https://zhuanlan.zhihu.com/p/1944712252512010607)
      * [WhisperLive](https://github.com/collabora/WhisperLive)ï¼š[å…è²»çš„å³æ™‚èªéŸ³è½‰æ–‡å­—å·¥å…·ï¼šWhisper Liveï¼Œç²¾æº–é«˜æ•ˆï¼Œæ”¯æ´å¤šèªè¨€](https://www.zhihu.com/tardis/zm/art/676939649)
      * [distil-whisper](https://github.com/huggingface/distil-whisper)ï¼š[èªéŸ³è¾¨è­˜çš„æœªä¾†å·²ä¾†-æ¢ç´¢Distil-Whisperï¼Œè¼•é‡ç´šAIçš„å¼·å¤§åŠ›é‡](https://zhuanlan.zhihu.com/p/666238999)
      * [insanely-fast-whisper](https://github.com/Vaibhavs10/insanely-fast-whisper)ï¼›[Insanely Fast Whisperï¼šè¶…å¿«é€Ÿçš„WhisperèªéŸ³è¾¨è­˜è…³æœ¬](https://www.wehelpwin.com/article/4532)
      * [Whisper-Finetune](https://github.com/yeyupiaoling/Whisper-Finetune/)
      * fine-tune-whisperï¼š[ä½¿ç”¨Transformers ç‚ºå¤šèªç¨®èªéŸ³è­˜åˆ¥ä»»å‹™å¾®èª¿Whisper æ¨¡å‹](https://huggingface.co/blog/zh/fine-tune-whisper)
      * [WhisperX](https://github.com/m-bain/whisperX)
      * [Faster-Whisperå°å½±ç‰‡é€²è¡Œé›™èªå­—å¹•è½‰éŒ„å¯¦è¸(Python3.10)](https://zhuanlan.zhihu.com/p/664892334)
      * [Whisperæ–·å¥ä¸å¤ å¥½ï¼Ÿç”¨AI LLMå’Œçµæ§‹åŒ–è³‡æ–™æ‰“é€ å®Œç¾å­—å¹•](https://juejin.cn/post/7526324030387994675)
*  **FunASR**
    * [FunASR: A Fundamental End-to-End Speech Recognition Toolkit](https://github.com/alibaba-damo-academy/FunASR)
    * [é˜¿é‡Œé”æ‘©é™¢é–‹æºå¤§å‹ç«¯åˆ°ç«¯èªéŸ³è­˜åˆ¥å·¥å…·åŒ…FunASR](https://zhuanlan.zhihu.com/p/634646731)
    * [é”æ‘©é™¢FunASRé›¢ç·šæ–‡ä»¶è½‰å¯«SDKç™¼å¸ƒ](https://zhuanlan.zhihu.com/p/642807244)
* **WeNet**
    * [58åŒåŸï¼šWeNetç«¯åˆ°ç«¯èªéŸ³è­˜åˆ¥å¤§è¦æ¨¡è½åœ°æ–¹æ¡ˆ](https://zhuanlan.zhihu.com/p/573133117)
    * [WeNet: Production First and Production Ready End-to-End Speech Recognition Toolkit](https://arxiv.org/pdf/2102.01547.pdf)
* [**PaddleSpeech**](https://github.com/PaddlePaddle/PaddleSpeech)
* [**Speech Brain**ï¼šA PyTorch-based Speech Toolkit](https://github.com/speechbrain/speechbrain)
* [**Kaldi 2**ï¼šFSA/FST algorithms, differentiable, with PyTorch compatibility.](https://github.com/k2-fsa/k2)
    * [Next-gen-Kaldi è¿‘æœŸé€²å±•](https://zhuanlan.zhihu.com/p/617877445)


<details>
<summary>2020/03-2021/01 é–‹ç™¼å¿ƒå¾—</summary>
èªéŸ³è¾¨è­˜ï¼ˆspeech recognitionï¼‰æŠ€è¡“ï¼Œä¹Ÿè¢«ç¨±ç‚ºè‡ªå‹•èªéŸ³è¾¨è­˜ï¼ˆè‹±èªï¼šAutomatic Speech Recognition, ASRï¼‰ã€é›»è…¦èªéŸ³è­˜åˆ¥ï¼ˆè‹±èªï¼šComputer Speech Recognitionï¼‰æˆ–æ˜¯èªéŸ³è½‰æ–‡å­—è­˜åˆ¥ï¼ˆè‹±èªï¼šSpeech To Text, STTï¼‰ï¼Œå…¶ç›®æ¨™æ˜¯ä»¥é›»è…¦è‡ªå‹•å°‡äººé¡çš„èªéŸ³å…§å®¹è½‰æ›ç‚ºç›¸æ‡‰çš„æ–‡å­—ï¼›è·Ÿå°å¤¥ä¼´å€‘ä¸€èµ·å˜—è©¦éNEMOé‚„æœ‰Kaldiã€MASRã€VOSKï¼Œwav2vecä»¥åŠGoogleã€Azureç­‰APIï¼Œæ›´åˆ¥èªªå¾Œä¾†é™¸çºŒåˆå‡ºç¾SpeechBrainã€å‡ºé–€å•å•çš„WeNetè·Ÿé¨°è¨ŠPIKAç­‰ã€‚ç›®å‰å·²çŸ¥å¯è¨“ç·´è²å­¸æ¨¡å‹(AM)ä¸­æ–‡èªéŸ³(ä¸­åœ‹ç™¼éŸ³/ç”¨èªï¼Œå¯æƒœé‚„æ²’è‡ºç£è¼ƒé è­œçš„)å…¬é–‹æ•¸æ“šå¦‚ï¼šMagic-Data_Mandarin-Chinese-Read-Speech-Corpusã€aidatatangã€aishell-1 ã€aishell-2ç­‰ç´„2000å¤šå°æ™‚(aishellç›®å‰å·²åˆ°4ï¼Œä½†æƒ³å•†ç”¨è‡³å°‘å¾—ç ´è¬å°æ™‚è¼ƒé è­œ)ï¼›å†æ­é…èªè¨€æ¨¡å‹(LM)ï¼Œç„¶å¾ŒåŸºæ–¼å„ç¨®æ¼”ç®—æ³•æ¶æ§‹å„ªåŒ–å„æœ‰å„ªç¼ºé»ï¼Œæ•ˆæœä¹Ÿå„æœ‰å„ªåŠ£ã€‚èˆ‡èªªè©±äººè¾¨è­˜åŠèªªè©±äººç¢ºèªä¸åŒï¼Œå¾Œè€…å˜—è©¦è¾¨è­˜æˆ–ç¢ºèªç™¼å‡ºèªéŸ³çš„èªªè©±äººè€Œéå…¶ä¸­æ‰€åŒ…å«çš„è©å½™å…§å®¹ã€‚ èªéŸ³è¾¨è­˜æŠ€è¡“çš„æ‡‰ç”¨åŒ…æ‹¬èªéŸ³æ’¥è™Ÿã€èªéŸ³å°èˆªã€å®¤å…§è£ç½®æ§åˆ¶ã€èªéŸ³æ–‡ä»¶æª¢ç´¢ã€ç°¡å–®çš„è½å¯«è³‡æ–™éŒ„å…¥ç­‰ã€‚èªéŸ³è¾¨è­˜æŠ€è¡“èˆ‡å…¶ä»–è‡ªç„¶èªè¨€è™•ç†æŠ€è¡“å¦‚æ©Ÿå™¨ç¿»è­¯åŠèªéŸ³åˆæˆæŠ€è¡“ç›¸çµåˆï¼Œå¯ä»¥æ§‹å»ºå‡ºæ›´åŠ è¤‡é›œçš„æ‡‰ç”¨ï¼Œä¾‹å¦‚èªéŸ³åˆ°èªéŸ³çš„ç¿»è­¯ã€‚èªéŸ³è¾¨è­˜æŠ€è¡“æ‰€æ¶‰åŠçš„é ˜åŸŸåŒ…æ‹¬ï¼šè¨Šè™Ÿè™•ç†ã€åœ–å‹è­˜åˆ¥ã€æ¦‚ç‡è«–å’Œè³‡è¨Šç†è«–ã€ç™¼è²æ©Ÿç†å’Œè½è¦ºæ©Ÿç†ã€äººå·¥æ™ºæ…§ç­‰ç­‰ã€‚
</details>
<br><br>


# ä¸­æ–‡èªè€…(è²ç´‹)è­˜åˆ¥ (Chinese Speaker Recognition)

[https://www.twman.org/AI/ASR/SpeakerRecognition](https://www.twman.org/AI/ASR/SpeakerRecognition)

æ‰¾åˆ°æè¿°ç‰¹å®šå°è±¡çš„è²ç´‹ç‰¹å¾µï¼Œé€šéè²éŸ³åˆ¤åˆ¥èªªè©±äººèº«ä»½çš„æŠ€è¡“ï¼›å€ŸåŠ©ä¸åŒäººçš„è²éŸ³ï¼Œåœ¨èªè­œåœ–çš„åˆ†ä½ˆæƒ…æ³ä¸åŒé€™ä¸€ç‰¹å¾µï¼Œå»å°æ¯”å…©å€‹äººçš„è²éŸ³ï¼Œä¾†åˆ¤æ–·æ˜¯å¦åŒäººã€‚

### **ç›¸é—œè«–æ–‡**
* [Wespeaker: A Research and Production oriented Speaker Embedding Learning Toolkit](https://www.alphaxiv.org/zh/overview/2210.17016v2)
* [SincNetï¼šSpeaker Recognition from Raw Waveform with SincNet](https://www.alphaxiv.org/zh/overview/1808.00158v3)

### **ç›¸é—œé€£çµ**
* [Wespeaker v1.2.0 ç™¼å¸ƒï¼šæ–°å¢SSL Recipeï¼ŒNIST SRE æ•¸æ“šé›†æ”¯æŒ, PLDA åŠè‡ªé©æ‡‰ä»£ç¢¼ç­‰](https://zhuanlan.zhihu.com/p/645726183)
* [ASV-Subtoolsè²ç´‹è­˜åˆ¥å¯¦æˆ°](https://speech.xmu.edu.cn/2022/1124/c18207a465302/page.htm)
* [ICASSP 2023èªªè©±äººè­˜åˆ¥æ–¹å‘è«–æ–‡åˆé›†ï¼ˆä¸€ï¼‰](https://zhuanlan.zhihu.com/p/645560614)
* [è²ç´‹è­˜åˆ¥åŸç†](https://www.zhihu.com/question/30141460)
* [æ·±åº¦å­¸ç¿’åœ¨è²ç´‹è­˜åˆ¥ä¸­çš„æ‡‰ç”¨](https://yutouwd.github.io/posts/600d0d5d/)
* [ç›¸é—œè²ç´‹è­˜åˆ¥ä»‹ç´¹åŒ¯æ•´](http://xinguiz.com/category/#/å£°çº¹è¯†åˆ«)
* [æé«˜è²ç´‹è¾¨è­˜æ­£ç¢ºç‡ æ›´æ·»é˜²ç–«æ–°åˆ©å™¨](https://www.nchc.org.tw/Message/MessageView/3731?mid=43)
* [CN-Celeb-AV: å¤šå ´æ™¯è¦–è½å¤šæ¨¡æ…‹æ•¸æ“šé›†ç™¼å¸ƒ](https://zhuanlan.zhihu.com/p/647786644)

<details>
<summary>2020/03/08-2020/08/29 é–‹ç™¼å¿ƒå¾—</summary>
æŠ•å…¥ç´„150å¤©ã€‚é€šå¸¸æˆ‘å€‘æ˜¯æ€æ¨£é–‹å§‹é …ç›®çš„ç ”ç©¶èˆ‡é–‹ç™¼ï¼Ÿé¦–å…ˆæœƒå…ˆç›¡å¯èƒ½çš„æŠŠ3å¹´å…§çš„å­¸è¡“è«–æ–‡æˆ–æ¯”è³½ç­‰SOTAéƒ½æŸ¥åˆ°ï¼Œç„¶å¾Œåˆ†å·¥é–±è®€æ‰¾åˆ°ç›¸é—œçš„æ•¸æ“šé›†å’Œè«–æ–‡åŠç›¸é—œå¯¦ä½œï¼›åŒæ™‚æœƒæ‰¾åˆ°ç›®å‰å·²æœ‰ç›¸é—œç”¢å“çš„å…¬å¸(å«æ–°å‰µ)åŠä»–å€‘æäº¤çš„å°ˆåˆ©ï¼Œé€™éƒ¨ä»½é€šå¸¸å†èŠ±ç´„30å¤©çš„æ™‚é–“ï¼›é€šå¸¸å°±æ˜¯é€é Google patensã€paper with codesã€arxivç­‰ç­‰ã€‚

è²ç´‹è­˜åˆ¥é€™å¡Šåœ¨å°å²¸æŸ¥åˆ°éå¸¸å¤šçš„æ–°å‰µå…¬å¸ï¼Œä¾‹å¦‚: åœ‹éŸ³æ™ºèƒ½åœ¨æˆ‘å€‘ç ”ç©¶é–‹ç™¼éç¨‹å°±æ˜¯ä¸€ç›´è¢«ç•¶åšç›®æ¨™çš„æ–°å‰µå…¬å¸ã€‚å¯ä»¥å…ˆçœ‹ä¸€ä¸‹ä¸Šæ–¹çš„DEMOå½±ç‰‡æ•ˆæœï¼›ç„¶å¾Œä»‹ç´¹ç›¸é—œå¯¦é©—çµæœå‰ï¼Œé¿å…ä¹‹å¾Œæœ‰äººé‚„é™¸çºŒè¸©åˆ°æˆ‘å€‘è¸©éçš„å‘ï¼›éœ€æ³¨æ„çš„æ˜¯ä¸Šè¿°å¾ˆå¤šæ•¸æ“šé›†éƒ½æ˜¯æ”¾åœ¨å°å²¸åƒæ˜¯ç™¾åº¦é›²ç›¤ç­‰ï¼Œç™¾åº¦æ˜¯ç›´æ¥å°é–å°ç£çš„IPï¼Œæ‰€ä»¥ä½ æ‰“ä¸é–‹æ˜¯å¾ˆæ­£å¸¸çš„ï¼›å¦å¤–åƒæ˜¯voxcelabæ˜¯åˆ‡æˆ7ä»½ï¼Œä¸‹è¼‰å®Œå†åˆèµ·ä¾†ä¹Ÿè¦èŠ±ä¸Šä¸å°‘æ™‚é–“ï¼Œaishellã€CMDS, TIMIT æ¯”èµ·ä¾†ç›¸å°å¥½è™•ç†å°±æ˜¯ã€‚

ç°¡å–®ç¸½çµç‚ºï¼š1. å¹¾ç¨® vector çš„æŠ½å– (i-vector, d-vector, x-vector) è·Ÿ 2. æ¨¡å‹æ¶æ§‹ (CNN, ResNet) å’Œèª¿åƒï¼Œå†ä¾†å°±æ˜¯ 3. è©•åˆ†æ–¹å¼ (LDA, PLDA (Probabilistic Linear Discriminant Analysis)) ç­‰ç­‰å¹¾ç¨®çµ„åˆï¼›æˆ‘å€‘ä¹Ÿä½¿ç”¨äº† kaldi å…¶ä¸­å…§é™„çš„åŠŸèƒ½ï¼Œå…‰æ˜¯ kaldi å°±åˆæŠ•å…¥äº†ä¸å°‘æ™‚é–“å’Œç²¾åŠ› ! å…¶å¯¦æ¯”èµ·è‡ªç„¶èªè¨€è™•ç†åšè²ç´‹è­˜åˆ¥ï¼Œæœ€å°çš„å‘è«éæ–¼é›–ç„¶æ•¸æ“šé›†ä¸æ˜¯å¾ˆå®¹æ˜“ç²å–ï¼Œä½†æ˜¯è²éŸ³æ˜¯å¯ä»¥è‡ªè¡Œç”¨ç¨‹å¼åŠ å·¥åšåˆ‡å‰²åˆä½µï¼Œç„¶å¾Œå› ç‚ºå ´æ™¯é™åˆ¶ï¼ŒéŒ„è²ç´‹æ™‚çš„æ™‚é•·é —çŸ­ï¼Œé‚„å¾—è™•ç†éè¨»å†Šè²ç´‹çš„è™•ç†ï¼Œæ‰€ä»¥å‰å‰å¾Œå¾ŒèŠ±äº†å¾ˆå¤šæ™‚é–“åœ¨å°‡ç›¸é—œçš„æ•¸æ“šæ­é…è©•åˆ†æ¨¡å¼èª¿æ•´ï¼Œä¹Ÿç®—æ˜¯å€‹å¤§å·¥ç¨‹ã€‚

**æŠ€è¡“æŒ‡æ¨™ï¼š**
éŒ¯èª¤æ‹’çµ•ç‡(False Rejection Rate, FRR)ï¼šåŒé¡çš„å…©äººè¢«ç³»çµ±åˆ¤åˆ¥ç‚ºä¸åŒé¡ã€‚FRRç‚ºèª¤åˆ¤æ¡ˆä¾‹åœ¨æ‰€æœ‰åŒé¡åŒ¹é…æ¡ˆä¾‹ä¸­çš„æ¯”ä¾‹
éŒ¯èª¤æ¥å—ç‡(False Acceptance Rate, FAR)ï¼šä¸åŒé¡çš„å…©äººè¢«ç³»çµ±åˆ¤ç‚ºåŒé¡ã€‚FARç‚ºæ¥å—æ¡ˆä¾‹åœ¨æ‰€æœ‰ç•°é¡åŒ¹é…æ¡ˆä¾‹ä¸­çš„æ¯”ä¾‹
ç­‰éŒ¯èª¤ç‡(Equal Error Rate, EER)ï¼šèª¿æ•´thresholdï¼Œç•¶FRR=FARæ™‚ï¼ŒFRRå’ŒFARçš„æ•¸å€¼ç¨±ç‚ºç­‰éŒ¯èª¤ç‡
æº–ç¢ºç‡(Accuracyï¼ŒACC)ï¼šACC=1-min(FAR+FRR)

**é€Ÿåº¦ï¼š**
Real Time Factor å¯¦æ™‚æ¯”:è¡¡é‡æå–æ™‚é–“è·ŸéŸ³é »æ™‚é•·çš„é—œä¿‚ï¼Œex:1ç§’å¯ä»¥è™•ç†80sçš„éŸ³é »ï¼Œå¯¦æ™‚æ¯”=1:80ï¼›é©—è­‰æ¯”å°é€Ÿåº¦ï¼šå¹³å‡æ¯ç§’èƒ½é€²è¡Œçš„è²ç´‹æ¯”å°æ¬¡æ•¸
ROCæ›²ç·šï¼šæè¿°FARå’ŒFRRé–“è®ŠåŒ–çš„æ›²ç·šï¼ŒXè»¸ç‚ºFAR,Yè»¸ç‚ºFRRã€‚
é–¥å€¼ï¼šç•¶åˆ†æ•¸è¶…éé–¥å€¼æ‰åšå‡ºæ¥å—æ±ºå®šã€‚<br><br>  
</details>
<br><br>

# ä¸­æ–‡èªéŸ³å¢å¼·(å»å™ª) (Chinese Speech Enhancement)

[https://www.twman.org/AI/ASR/SpeechEnhancement](https://www.twman.org/AI/ASR/SpeechEnhancement)

[https://huggingface.co/spaces/DeepLearning101/Speech-Quality-Inspection_Meta-Denoiser](https://huggingface.co/spaces/DeepLearning101/Speech-Quality-Inspection_Meta-Denoiser)

æ‰¾åˆ°æè¿°ç‰¹å®šè²éŸ³ç‰¹å¾µï¼Œä¸¦å°‡å…¶å»é™¤ä»¥æé«˜è³ªé‡ï¼›å¾å«é›œè¨Šçš„èªéŸ³ä¿¡è™Ÿä¸­æå–å‡ºç´”æ·¨èªéŸ³çš„éç¨‹

### **ç›¸é—œè«–æ–‡**
* [Real Time Speech Enhancement in the Waveform Domain](https://www.alphaxiv.org/abs/2006.12847v3)

### **ç›¸é—œé€£çµ**
* 2024-12-07ï¼š[ClearVoice: Speech Enhancement](https://github.com/modelscope/ClearerVoice-Studio)ï¼š[é˜¿é‡Œå·´å·´é–‹æºè¶…å¼·èªéŸ³è™•ç†ç¥å™¨ï¼ŒèªéŸ³åˆ†é›¢ã€éŸ³è¨Šè¦–è¨Šèªªè©±è€…æ“·å–ç­‰åŠŸèƒ½ä¸€ç«™å¼è§£æ±ºã€‚](https://juejin.cn/post/7445237715863093275)ï¼Œ[HuggingFace Space Demo](https://huggingface.co/spaces/alibabasglab/ClearVoice)
* https://github.com/facebookresearch/denoiser
* https://www.youtube.com/watch?v=77cm_MVtLfk

<details>
<summary>2020/08/30-2021/01/25 é–‹ç™¼å¿ƒå¾—</summary>
åˆ†çµ„æŠ•å…¥ç´„150å¤©ï¼›èªªåˆ°æœƒåšèªéŸ³å¢å¼·(å»å™ªéŸ³)ï¼Œé€™ä¸€åˆ‡çœŸçš„åªæ˜¯å› ç‚ºé‚£æœ‰ä¸€é¢ä¹‹ç·£çš„åœ–éˆçå¤§ç¥åœ¨FBç™¼æ–‡ä»‹ç´¹FAIRçš„æœ€æ–°æˆæœï¼›è€Œå™ªéŸ³å»é™¤ä½ å¯ä»¥è·Ÿå¦å¤–ä¸€å€‹è²éŸ³åˆ†é›¢åšè¯æƒ³ï¼ŒåŸºæœ¬æ¦‚å¿µå…¶å¯¦å·®ä¸å¤šï¼Œåªæ˜¯å™ªéŸ³å»é™¤æ˜¯æŠŠéäººè²çµ¦å»é™¤ (è¨˜å¾—æ³¨æ„ä¸€ä¸‹æ˜¯ä¸æ˜¯å¤šé€šé“)ï¼›è€Œåšé€™å€‹é …ç›®æ™‚ï¼Œä¸€æ¨£ä¹Ÿæ˜¯åŒ¯æ•´æº–å‚™äº†ç›¸ç•¶å¤šçš„å­¸è¡“è«–æ–‡å’Œå¯¦é©—çµæœ (å¦‚ä¸‹æ‰€é™„) ï¼›åšèªéŸ³æ„Ÿè¦ºä¸Šæ•¸æ“šä¹Ÿæ˜¯å¾ˆé‡è¦ï¼Œä½†å™ªéŸ³å»é™¤ç›¸å°çš„æ•¸æ“šé›†å°±æ¯”è¼ƒå¥½è™•ç†ï¼Œç¶²è·¯ä¸Šéƒ½å¯ä»¥æ‰¾åˆ°ï¼Œåªè¦é€²è¡Œå‰å¾Œèª¿æ•´åˆä½µï¼Œå°±å¯ä»¥ç”¢å‡ºæ•¸é‡é —å¤§çš„æ•¸æ“šé›†ï¼Œå”¯ä¸€éœ€è¦è€ƒé‡çš„å°±æ˜¯ä½ çš„ GPU å¤ ä¸å¤ å¤§æ•´å€‹åƒä¸‹äº†ï¼Œé‚„æœ‰ä½ é€™äº›æ•¸æ“šé›†è£¡çš„äººè²æ˜¯ä¸æ˜¯ä¸€æ¨£æ˜¯è‹±æ–‡ï¼Œæˆ–è€…æ˜¯ä½ æƒ³è¦ä¸­æ–‡çš„æ•ˆæœï¼Ÿé †é“ä¸€ææœ€å¾Œæˆ‘å€‘çš„æ¨¡å‹å¤§å°æ˜¯ç¶“éå„ªåŒ–çš„9 MBï¼Œè€Œ RTF æ˜¯ 0.08ã€‚
</details>
<br><br>

# ä¸­æ–‡èªè€…åˆ†é›¢(åˆ†å‰²) (Chinese Speaker Separation)

https://www.twman.org/AI/ASR/SpeechSeparation

https://huggingface.co/spaces/DeepLearning101/Speech-Separation

å¾å¤šå€‹è²éŸ³ä¿¡è™Ÿä¸­æå–å‡ºç›®æ¨™ä¿¡è™Ÿï¼›å¤šå€‹èªªè©±äººæƒ…æ³çš„èªéŸ³è¾¨è­˜å•é¡Œï¼Œæ¯”å¦‚é›å°¾é…’æœƒä¸Šå¾ˆå¤šäººè¬›è©±

### **ç›¸é—œè«–æ–‡**

* Stabilizing Label Assignment for Speech Separation by Self-supervised Pre-trainingï¼šhttps://arxiv.org/abs/2010.15366
    * https://github.com/SungFeng-Huang/SSL-pretraining-separation
* Self-supervised Pre-training Reduces Label Permutation Instability of Speech Separationï¼šhttps://arxiv.org/pdf/2010.15366v1.pdf
    * https://github.com/SungFeng-Huang/SSL-pretraining-separation
* Sudo rm -rf: Efficient Networks for Universal Audio Source Separationï¼šhttps://arxiv.org/abs/2007.06833
    * https://github.com/asteroid-team/asteroid/blob/master/asteroid/models/sudormrf.py 
    * https://github.com/etzinis/sudo_rm_rf   
* Dual-Path Transformer Network: Direct Context-Aware Modeling for End-to-End Monaural Speech Separationï¼šhttps://arxiv.org/pdf/2007.13975v3.pdf
* Dual-path RNN: efficient long sequence modeling for time-domain single-channel speech separationï¼šhttps://arxiv.org/pdf/1910.06379.pdf
    * https://github.com/JusperLee/Dual-path-RNN-Pytorch
    * [é–±è®€ç­†è¨˜â€Dual-path RNN for Speech Separationâ€œ](https://zhuanlan.zhihu.com/p/104606356)

### **ç›¸é—œé€£çµ**
* 2025-06-03ï¼š[SoloSpeech](https://github.com/WangHelin1997/SoloSpeech)ï¼›[é«˜å“è³ªèªéŸ³è™•ç†æ¨¡å‹ï¼Œä¸€éµæå–æŒ‡å®šèªªè©±è€…éŸ³è¨Šä¸¦æå‡æå–éŸ³è¨Šæ¸…æ™°åº¦å’Œå“è³ª](https://zhuanlan.zhihu.com/p/1913305854289097038)
* 2024-12-07ï¼š[ClearVoice: Speech Enhancement](https://github.com/modelscope/ClearerVoice-Studio)ï¼š[é˜¿é‡Œå·´å·´é–‹æºè¶…å¼·èªéŸ³è™•ç†ç¥å™¨ï¼ŒèªéŸ³åˆ†é›¢ã€éŸ³è¨Šè¦–è¨Šèªªè©±è€…æ“·å–ç­‰åŠŸèƒ½ä¸€ç«™å¼è§£æ±ºã€‚](https://juejin.cn/post/7445237715863093275)ï¼Œ[HuggingFace Space Demo](https://huggingface.co/spaces/alibabasglab/ClearVoice)
* [ICASSP2023è«–æ–‡ä»£ç¢¼é–‹æºï½œTOLDèƒ½å°æ··ç–ŠèªéŸ³å»ºæ¨¡çš„èªªè©±äººæ—¥èªŒæ¡†æ¶](https://zhuanlan.zhihu.com/p/650346578)
* [ICASSP 2023è«–æ–‡æ¨¡å‹é–‹æºï½œèªéŸ³åˆ†é›¢Mossformer](https://zhuanlan.zhihu.com/p/609728122)


<details>
<summary>2020/08/30-2021/01/25 é–‹ç™¼å¿ƒå¾—</summary>
æŠ•å…¥ç´„150å¤©ã€‚å¦‚åŒèªéŸ³è¸©çš„å‘ä¾†èªªï¼Œæ¯”è¼ƒå¸¸ç¢°åˆ°å› ç‚ºç¶²è·¯æ¶æ§‹åœ¨åšåƒæ•¸èª¿æ•´æ™‚å°è‡´losså£æ‰ç­‰ç­‰ï¼Œè€Œå› æ•¸æ“šé›†é€ æˆçš„å•é¡Œå°‘å¾ˆå¤šï¼Œç¶²è·¯ä¸Šä¹Ÿæ¯”è¼ƒå®¹æ˜“æ‰¾åˆ°æ›´å¤šçš„æ•¸æ“šé›†ï¼Œç„¶å¾Œä¹Ÿæœ‰éå¸¸å¤šçš„æ¯”è³½æœ‰å„ç¨®æ¨¡å‹æ¶æ§‹çš„çµæœå¯ä»¥åƒè€ƒï¼Œä½†æ˜¯ä¸€æ¨£æ˜¯è‹±æ–‡æ•¸æ“šï¼Œè€ŒèªéŸ³å‘æœ€å¥½çš„å°±æ˜¯åªè¦æœ‰äº†åƒæ˜¯ aishell ç­‰çš„æ•¸æ“šé›†ï¼Œä½ æƒ³è¦åˆ‡å‰²æˆ–åˆä½µæˆä¸€å€‹èªéŸ³ï¼Œéƒ½ä¸æ˜¯å¤ªå¤§çš„å•é¡Œï¼›ä¾‹å¦‚æˆ‘å€‘å°±æ˜¯æŠŠæ•¸æ“šé›†æ‰“æ•£æ··åˆï¼Œå†å¾ä¸­éš¨æ©ŸæŒ‘é¸å…©å€‹äººï¼Œç„¶å¾Œå†å¾ä¸­åˆ†åˆ¥æŒ‘å‡ºèªéŸ³åšæ··åˆï¼›å¦‚æ˜¯é•·åº¦ä¸åŒï¼Œé¸æ“‡çŸ­è€…ç‚ºåƒè€ƒï¼Œå°‡é•·è€…åˆ‡åˆ°èˆ‡çŸ­è€…ç›¸åŒï¼›æœ€å¾Œç”¢å‡ºç´„ trainï¼š 5è¬å¤šç­†ï¼Œç´„ 32å°æ™‚ã€valï¼š1è¬å¤šç­†èªéŸ³ï¼Œç´„10å°æ™‚ã€testï¼š9,åƒå¤šç­†èªéŸ³ï¼Œç´„ 6å°æ™‚ï¼Œè€Œé€™å€‹æ•¸æ“šé›†æ˜¯å…©å…©å®Œå…¨é‡ç–Šï¼Œå¾Œä¾†ç‚ºäº†è™•ç†å…©å…©äº’ä¸å®Œå…¨é‡ç–Šï¼Œå†æ¬¡å¦å¤–ç”¢å‡ºäº†é€™æ¨£çš„æ•¸æ“šé›†ï¼štrainï¼š9è¬å¤šç­†èªéŸ³ï¼Œè¨ˆ112å°æ™‚ã€valï¼š2è¬å¤šç­†èªéŸ³ï¼Œè¨ˆ 26.3 å°æ™‚ã€testï¼š2è¬å¤šç­†èªéŸ³ï¼Œè¨ˆ 29.4 å°æ™‚ã€‚

ä¸­é–“ä¹Ÿæ„å¤–ç™¼ç¾äº†Google brain çš„ wavesplitï¼Œåœ¨æœ‰å™ªéŸ³åŠå…©å€‹äººåŒæ™‚è¬›è©±æƒ…å½¢ä¸‹ï¼Œæ„Ÿè¦ºæ•ˆæœé‚„ä¸å·®ï¼Œä½†æ²’æ‰¾åˆ°ç›¸é—œçš„codeï¼Œæœªèƒ½é€²ä¸€æ­¥é©—è­‰æˆ–æ˜¯å˜—è©¦æ›´æ”¹æ•¸æ“šé›†ã€‚é‚„æœ‰åˆæ˜¯é‚£ä½æœ‰ä¸€èµ·ç”¨é¤ä¹‹ç·£çš„æ·±åº¦å­¸ç¿’å¤§ç¥ Yann LeCunç¹¼ç™¼æ–‡ä»‹ç´¹ å®Œå»å™ªå¾Œï¼Œåˆç™¼æ–‡ä»‹ç´¹äº†èªéŸ³åˆ†é›¢ï¼›å¾Œä¾†é‚„æœ‰åƒæ˜¯æœ€æ—©æ‡‰ç”¨åœ¨NLPçš„Transformerç­‰Dual-path RNN (DP-RNN) æˆ– DPT-NET (Dual-path transformer) ç­‰æ‡‰ç”¨åœ¨èªéŸ³å¢å¼·/åˆ†å‰²ï¼Œå¦å¤–VoiceFilterã€TasNet è·Ÿ Conv-TasNeté‚„æœ‰sudo-rmç­‰ç­‰ä¹Ÿæ˜¯èªéŸ³åˆ†å‰²ç›¸é—œï¼Œç•¶ç„¶æ›´ä¸èƒ½éŒ¯éè‡ºå¤§é›»æ©Ÿæå®æ¯…è€å¸«ä¸€ç¯‡SSL-pretraining-separationçš„è«–æ–‡ (å‹™å¿…çœ‹å®Œè‡ºå¤§é›»æ©Ÿæå®æ¯…è€å¸«çš„å½±ç‰‡)ï¼Œæœ€å¾Œä¹Ÿæ˜¯å¤šè™§æè€å¸«åŠç¬¬ä¸€ä½œè€…é»ƒåŒå­¸çš„è§£æƒ‘ï¼Œç„¶å¾Œå°å¤¥ä¼´å€‘æ‰åˆæ›´æ·±å…¥çš„ç¢ºèªä¸¦ä¸”è§£æ±ºå•é¡Œã€‚
é€™è£¡åšæ•¸æ“šæ™‚ç›¸å°ç°¡å–®ä¸€é»ï¼Œç›´æ¥æ‰“æ•£æ··åˆï¼Œå†å¾ä¸­éš¨æ©ŸæŒ‘é¸å…©å€‹äººï¼Œç„¶å¾Œåˆ†åˆ¥æŒ‘å‡ºèªéŸ³åšæ··åˆï¼Œè‹¥é•·åº¦ä¸åŒï¼Œé¸æ“‡çŸ­è€…ç‚ºåƒè€ƒï¼Œå°‡é•·è€…åˆ‡åˆ°èˆ‡çŸ­è€…ç›¸åŒï¼Œå…©å…©å®Œå…¨é‡ç–Šæˆ–è€…å…©å…©äº’ä¸å®Œå…¨é‡ç–Šç­‰éƒ½å°æ•ˆæœæœ‰ä¸å°çš„å½±éŸ¿ï¼›åŒæ™‚ä¹Ÿç ”ç©¶äº†Data Parallel è·Ÿ Distributed Data Parallel çš„å·®ç•°ï¼Œä½†æ˜¯å¦‚ä½•æ‰èƒ½åœ¨ CPU ä¸Šè·‘å¾—åˆå¿«åˆæº–æ‰æ˜¯è½åœ°çš„é—œéµ
</details>
<br><br>

# ä¸­æ–‡èªéŸ³åˆæˆ (Chinese Speech Synthesis)

### **ç›¸é—œé€£çµ**

* [OpenAI-Edge-TTS](https://github.com/travisvn/openai-edge-tts)ï¼š[é–‹æºçš„å…è²»æ–‡å­—è½‰èªéŸ³APIæ¥å£ï¼Œè¨—ç®¡åœ¨GitHubä¸Š](https://mp.weixin.qq.com/s/lt9Vr0hR7wwyhqTh68gTkA)
* [fish-speech](https://huggingface.co/fishaudio/fish-speech-1.5)
  * [æ€§èƒ½è¶…éF5ã€CosySenseï¼Œä¸€æ–‡å¸¶ä½ ç†è«–+å¯¦æ“å¤šç¨®èªè¨€å…‹éš†æ•ˆæœ](https://mp.weixin.qq.com/s/z8L3lpEbQ1-bkD7MM6oLsw)
  * [fish-speech-gui](https://github.com/AnyaCoder/fish-speech-gui)ï¼›[Github](https://github.com/fishaudio/fish-speech/blob/main/docs/README.zh.md)ï¼›[Document](https://speech.fish.audio/zh/)
* 2025-08-15ï¼š[ZipVoiceï¼šCPU is all you need!](https://github.com/k2-fsa/ZipVoice)
* 2025-08-08ï¼š[KittenTTS](https://github.com/KittenML/KittenTTS)ï¼›[è¶…è¿·ä½  TTS æ¨¡å‹ï¼ˆå°æ–¼ 25 MBï¼‰](https://www.reddit.com/r/LocalLLaMA/comments/1mhyzp7/kitten_tts_sota_supertiny_tts_model_less_than_25/?tl=zh-hant)
* 2025-07-30ï¼š[Microsoft DragonV2.1](https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/personal-voice-upgraded-to-v2-1-in-azure-ai-speech-more-expressive-than-ever-bef/4435233)
* 2025-07-25ï¼š[Higgs Audio V2](https://github.com/boson-ai/higgs-audio)
    * [Github](https://github.com/boson-ai/higgs-audio)
    * [HF Space Playground](https://huggingface.co/spaces/smola/higgs_audio_v2)
    * [Boson AI Playground](https://www.boson.ai/demo/tts)
    * [ææ²Bç«™æ›´æ–°äº†ï¼æ•™ä½ æ‰‹æ“èªéŸ³å¤§æ¨¡å‹ï¼Œç¨‹å¼ç¢¼å…¨é–‹æºé‚„èƒ½åœ¨ç·šä¸Šè©¦ç©](https://zhuanlan.zhihu.com/p/1931365847840069074)
    * 2025-08-03ï¼š[Higgs audioå­¸æœƒäº†è¶Šå—èª](https://github.com/JimmyMa99/train-higgs-audio)
    * [https://mp.weixin.qq.com/s/k7PMihbveN8XUS-bvQOOsw](https://mp.weixin.qq.com/s/k7PMihbveN8XUS-bvQOOsw)
* 2025-07-23ï¼š[FreeAudio](https://freeaudio.github.io/FreeAudio/)ï¼›[AIéŸ³æ•ˆ90ç§’é•·æ™‚å¯æ§ç”Ÿæˆï¼ ã€Œç‹¼åš2ç§’ï¼ŒèŸ‹èŸ€é³´8ç§’ã€ç²¾æº–æå®š](https://mp.weixin.qq.com/s/gwfbwuQ91AF-WCzSVmTxNQ)
* 2025-07-14ï¼š[MOSS-TTSD](https://www.open-moss.com/en/moss-ttsd/)ï¼›[é‚±éŒ«éµ¬åœ˜éšŠé–‹æºMOSS-TTSDï¼ç™¾è¬å°æ™‚éŸ³é »è¨“ç·´](https://finance.sina.com.cn/tech/roll/2025-07-05/doc-infemitp8423057.shtml)
* 2025-06-05ï¼š[OpenAudio S1](https://huggingface.co/fishaudio/openaudio-s1-mini)ï¼›[é‡æ–°å®šç¾©æ–‡å­—è½‰èªéŸ³ï¼Œé‡‹æ”¾è²éŸ³çš„ç„¡é™æ½›èƒ½](https://zhuanlan.zhihu.com/p/1913864308212863691)ï¼›[å…¨çƒå”¯ä¸€é«˜å¯æ§å¤šèªè¨€TTS-OpenAudio-S1ï¼Œä¸¦é–‹æºminiç‰ˆ](https://zhuanlan.zhihu.com/p/1913736328702592271)
* 2025-03-30ï¼š[MegaTTS3](https://huggingface.co/spaces/ByteDance/MegaTTS3)ï¼š[å­—ç¯€è·³å‹•MegaTTS3 é–‹æºï¼š0.45B åƒæ•¸å¯¦ç¾é«˜å“è³ªä¸­è‹±é›™èªTTS èˆ‡èªéŸ³å…‹éš†](https://zhuanlan.zhihu.com/p/1889796359344857240)
* 2025-03-21ï¼š[Orpheus TTS](https://github.com/canopyai/Orpheus-TTS)
   * [Space@HuggingFace](https://huggingface.co/spaces/MohamedRashad/Orpheus-TTS)
   * [ä¸€æ¬¾å‰›å‰›é–‹æºçš„TTSèªéŸ³æ¨¡å‹ï¼ 25msè¶…ä½å»¶é²æ”¯æ´å³æ™‚å°è©±](https://zhuanlan.zhihu.com/p/31739692960)
* 2025-03-15ï¼š[CSM-Conversational Speech Generation Model](https://github.com/SesameAILabs/csm)
   * [AIèªéŸ³åˆæˆæ–°æ¨™ç«¿ï¼é–‹æº10å°æ™‚æ–¬ç²8K Starï¼ 1Båƒæ•¸å¯¦ç¾é›»å½±ç´šäººè²!](https://mp.weixin.qq.com/s/q4c1bUsRkpQHxFwpePsJLg)
   * [é©…å‹•ã€Œè¶…çœŸäººã€è™›æ“¬åŠ©ç†Mayaçš„å³æ™‚èªéŸ³å°è©±æ¨¡å‹CSM-1bé–‹æºï¼](https://zhuanlan.zhihu.com/p/30943039927)
* 2025-03-02ï¼š[Spark-TTS](http://github.com/SparkAudio/Spark-TTS)ï¼š[åŸºæ–¼å–®æµè§£è€¦èªéŸ³ä»¤ç‰Œçš„é«˜æ•ˆèƒ½æ–‡å­—è½‰èªéŸ³æ¨¡å‹](https://zhuanlan.zhihu.com/p/29631171989)
* 2025-03-01ï¼š[Step-Audio](https://github.com/stepfun-ai/Step-Audio)ï¼š[[ComfyUI]æœ€æ–°è²éŸ³è¤‡è£½æŠ€è¡“ï¼Œé…åˆæ•¸ä½äººç„¡æ•µäº†](https://mp.weixin.qq.com/s/HLYM5g8bJGCoytcoxOXzjA)
* 2024/11/30ï¼š[MockingBird](https://github.com/babysor/MockingBird)ï¼š[MockingBird é–‹æºèªéŸ³å…‹éš†ç¥å™¨ï¼Œ5 ç§’é€Ÿã€Œå¾©åˆ»ã€ è²éŸ³ï¼Œæ‘˜å¾—35.4k æ˜Ÿé–ƒè€€ä½³ç¸¾ï¼](https://mp.weixin.qq.com/s/4Ce-be5YMBTQn9aHX2OeaQ)
* 2024-11-02ï¼š[Kokoro-TTS](https://huggingface.co/spaces/hexgrad/Kokoro-TTS)ï¼š[Kokoro TTSï¼šæ–‡å­—è½‰èªéŸ³AI](https://kokorotts.net/zh-Hant)
* 2024/10/15ï¼š[é˜¿é‡Œæœ€å¼·TTSï¼ŒSTTå·¥å…·CosyVoiceï¼ŒSenseVoiceï¼Œåœ¨ComfyUIä¸­çš„ä½¿ç”¨ï¼Œè®“ä½ å¯¦ç¾æµæš¢å°è©±](https://mp.weixin.qq.com/s/Lvijhi3U8jg88C8_h5Gbww)
* 2024/10/15ï¼š[F5-TTSï¼šä¸Šæµ·äº¤å¤§é–‹æºè¶…é€¼çœŸè²éŸ³å…‹éš†TTSï¼Œ15ç§’å…‹éš†è²éŸ³](https://mp.weixin.qq.com/s/tWrjQfl2XkOO8GwwVyFoqw)
* 2024/09/09ï¼š[Parler-TTS](https://github.com/huggingface/parler-tts)ï¼š[Hugging Face é–‹æºTTS æ¨¡å‹ï¼ä¸€è¡ŒæŒ‡ä»¤å³å¯å®‰è£ï¼](https://mp.weixin.qq.com/s/uzYMnR6ole_RSPE_Es_thw)
* 2024/06/09ï¼š[ChatTTS](https://github.com/2noise/ChatTTS)ï¼š[é–‹æºæ–‡å­—è½‰èªéŸ³æ¨¡å‹æœ¬åœ°éƒ¨ç½²ã€APIä½¿ç”¨å’Œå»ºç«‹WebUIä»‹é¢](https://mp.weixin.qq.com/s/rL3vyJ_xEj7GGoKaxUh8_A)
* 2024/08/6ï¼š[VALL-E XèªéŸ³æ¨¡å‹ï¼Œæ‰‹æŠŠæ‰‹å¯¦æ“èªéŸ³è½‰æ–‡å­—å’Œè²éŸ³å…‹éš†](https://mp.weixin.qq.com/s/Fo8ESzbEfjZQNUUx_giJRA)
* MeloTTSï¼š[https://github.com/myshell-ai/MeloTTS](https://github.com/myshell-ai/MeloTTS)
   * [å¤šèªè¨€å³æ™‚æ–‡å­—è½‰èªéŸ³çš„é«˜å“è³ªå·¥å…·ï¼ç„¡GPUä¹Ÿå¯éˆæ´»ä½¿ç”¨ï¼](https://mp.weixin.qq.com/s/DSHabmduaUX5_aBedDhEFg)
* [GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)ï¼šGithub ç²å¾— 35.2k starçš„é–‹æºè²éŸ³å…‹éš†é …ç›®ï¼Œ1åˆ†é˜èªéŸ³è¨“ç·´TTSæ¨¡å‹
* [Deepgram](https://deepgram.com/)




<details éå¾€è³‡è¨Š close>
<summary><strong>éå¾€è³‡è¨Š</strong></summary>

- [GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS)ï¼š[GPT-SoVits: ä¸Šç·šå…©å¤©ç²å¾—äº†1.4k starçš„é–‹æºè²éŸ³å…‹éš†é …ç›®ï¼Œ1åˆ†é˜èªéŸ³è¨“ç·´TTSæ¨¡å‹](https://zhuanlan.zhihu.com/p/679547903)

- [Retrieval-based-Voice-Conversion-WebUI](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI)

- [Rectified Flow Matching èªéŸ³åˆæˆï¼Œä¸Šæµ·äº¤å¤§é–‹æº**](https://www.speechhome.com/blogs/news/1712396018944970752)ï¼šhttps://github.com/cantabile-kwok/VoiceFlow-TTS

- [coqui-ai TTS](https://github.com/coqui-ai/TTS)
    * [XTTS v2ç·šä¸Šé«”é©—](https://huggingface.co/spaces/coqui/xtts)
    * [coqui-ai TTS ç°¡è©•](https://www.speechhome.com/blogs/news/1726435660778311680)
    * [æ–°ä¸€ä»£é–‹æºèªéŸ³åº«CoQui TTSè¡åˆ°äº†GitHub 20.5k Star](https://zhuanlan.zhihu.com/p/661291996)
- [EmotiVoice](https://github.com/netease-youdao/EmotiVoice)
    * [æ­£å¼é–‹æºï¼ç¶²è·¯æ˜“æœ‰é“ä¸Šç·šã€Œæ˜“é­”è²ã€èªéŸ³åˆæˆå¼•æ“](https://zhuanlan.zhihu.com/p/666172336)

- Amphion@OpenMMLabï¼šhttps://github.com/open-mmlab/Amphion
- Barkï¼šhttps://github.com/suno-ai/bark
    * [æœ€å¼·æ–‡æœ¬è½‰èªéŸ³å·¥å…·ï¼šBarkï¼Œæœ¬åœ°å®‰è£+é›²ç«¯éƒ¨ç½²+åœ¨ç·šé«”é©—è©³ç´°æ•™ç¨‹](https://zhuanlan.zhihu.com/p/630900585)
    * [ä½¿ç”¨Transformers å„ªåŒ–æ–‡æœ¬è½‰èªéŸ³æ¨¡å‹Bark](https://zhuanlan.zhihu.com/p/651951136)
    * [GitHub é–‹æºç¥å™¨Barkæ¨¡å‹ï¼Œè®“æ–‡å­—è½‰èªéŸ³æ›´ç°¡å–®ï¼](https://www.speechhome.com/blogs/news/1724361984838864896)
- [Bert-VITS2](https://github.com/fishaudio/Bert-VITS2)
    * [æœ¬åœ°è¨“ç·´,é–‹ç®±å¯ç”¨,Bert-VITS2 V2.0.2ç‰ˆæœ¬æœ¬åœ°åŸºæ–¼ç¾æœ‰è³‡æ–™é›†è¨“ç·´](https://zhuanlan.zhihu.com/p/668211415)
    * [æ ©æ ©å¦‚ç”Ÿ,éŸ³è‰²å…‹éš†,Bert-vits2æ–‡å­—è½‰èªéŸ³æ‰“é€ é¬¼ç•œè¦–è¨Šå¯¦è¸](https://zhuanlan.zhihu.com/p/662885913)
- [æ¸…è¯å¤§å­¸LightGrad-TTSï¼Œä¸”æµå¼å¯¦ç¾](https://zhuanlan.zhihu.com/p/656012430)ï¼šhttps://github.com/thuhcsi/LightGrad

- [Wunjo AI: Synthesize & clone voices in English, Russian & Chinese](https://github.com/wladradchenko/wunjo.wladradchenko.ru)ï¼šhttps://huggingface.co/wladradchenko/wunjo.wladradchenko.ru

- [VALL-Eï¼šå¾®è»Ÿå…¨æ–°èªéŸ³åˆæˆæ¨¡å‹å¯ä»¥åœ¨3ç§’å…§å¾©åˆ¶ä»»ä½•äººçš„è²éŸ³](https://zhuanlan.zhihu.com/p/598473227)
    * [éå®˜æ–¹](https://lifeiteng.github.io/valle/)ï¼šTo avoid abuse, Well-trained models and services will not be provided.
- [BLSTM-RNNã€Deep Voiceã€Tacotronâ€¦ä½ éƒ½æŒæ¡äº†å—ï¼Ÿä¸€æ–‡æ€»ç»“è¯­éŸ³åˆæˆå¿…å¤‡ç»å…¸æ¨¡å‹ï¼ˆä¸€ï¼‰](https://new.qq.com/rain/a/20221204A02GIT00)

- [Tacotron2ã€GSTã€Glow-TTSã€Flow-TTSâ€¦ä½ éƒ½æŒæ¡äº†å—ï¼Ÿä¸€æ–‡æ€»ç»“è¯­éŸ³åˆæˆå¿…å¤‡ç»å…¸æ¨¡å‹ï¼ˆäºŒï¼‰](https://cloud.tencent.com/developer/article/2250062)

- [å‡ºé–€å•å•MeetVoice, è®“åˆæˆè²éŸ³ä»¥å‡äº‚çœŸ](https://zhuanlan.zhihu.com/p/92903377)
</details>
